{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# MINST Dataset\r\n",
                "# https://deepai.org/dataset/mnist\r\n",
                "\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "import numpy as np\r\n",
                "from random import randint\r\n",
                "import copy"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "with open(\"mnist/train-images.idx3-ubyte\", \"r\") as images,\\\r\n",
                "    open(\"mnist/train-labels.idx1-ubyte\", \"r\") as labels:\r\n",
                "\r\n",
                "    # --- Header (images)\r\n",
                "    print('▶ Processing header')\r\n",
                "    header_images = np.fromfile(images, dtype='>i', count=4) # big-endian integer (32-bit, 4 bytes)\r\n",
                "\r\n",
                "    magic_number = header_images[0]\r\n",
                "    img_count = header_images[1]\r\n",
                "    row_count = header_images[2]\r\n",
                "    col_count = header_images[3]\r\n",
                "    pixel_count = row_count*col_count\r\n",
                "\r\n",
                "    print(f\"#images\\t\\t {img_count}\")\r\n",
                "    print(f\"#rows\\t\\t {row_count}\")\r\n",
                "    print(f\"#cols\\t\\t {col_count}\")\r\n",
                "    print(f\"#pixels\\t\\t {pixel_count} ({row_count}*{col_count})\")\r\n",
                "\r\n",
                "\r\n",
                "    # --- Header (labels)\r\n",
                "    header_labels = np.fromfile(labels, dtype='>i', count=2) # big-endian integer (32-bit, 4 bytes)\r\n",
                "    magic_number = header_labels[0]\r\n",
                "    label_count = header_labels[1]\r\n",
                "    \r\n",
                "    print(f\"#labels\\t\\t {label_count}\")\r\n",
                "\r\n",
                "\r\n",
                "    # --- Prepare for training & start\r\n",
                "    batch_size = 10\r\n",
                "    print()\r\n",
                "    print('▶ Processing images')\r\n",
                "    model = NN([784, 16, 16, 10], batch_size, 0.1)\r\n",
                "\r\n",
                "    # for i in range(60000/batch_size): # in range(label_count / batch_size)\r\n",
                "    for i in range(2): # no. of total batches\r\n",
                "        # --- Process one batch\r\n",
                "        print(f'▶▶▶ Processing {i+1}. batch')\r\n",
                "        for j in range(batch_size):\r\n",
                "            offset = i*batch_size + j\r\n",
                "            # Image\r\n",
                "            img = np.fromfile(images, dtype=np.ubyte, count=28*28, offset=28*28*offset)\r\n",
                "            plt.imshow(img.reshape((28, 28)), cmap=\"gray\")\r\n",
                "\r\n",
                "            # Label\r\n",
                "            label = np.fromfile(labels, dtype=np.ubyte, count=1, offset=offset)[0]\r\n",
                "            print(f\"Processing image with label {label}\")\r\n",
                "\r\n",
                "            plt.show()\r\n",
                "\r\n",
                "            model.train(img, label)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 330,
            "source": [
                "# --- Our model\r\n",
                "\r\n",
                "# First layer:      784 neurons (pixels of our image with gray-scale values from 0..255)\r\n",
                "# Hidden Layer 1:   16 neurons\r\n",
                "# Hidden Layer 2:   16 neurons\r\n",
                "# Output Layer:     10 layers (representing number 0..9)\r\n",
                "\r\n",
                "# Layer1 ------------------- Layer2 ------------------- Layer3 ------------------- Layer4\r\n",
                "# 784 (28*28)                  16                        16                   10 (digits 0-9)              <- #neurons\r\n",
                "# input layer               hidden layer 1          hidden layer 2              output layer\r\n",
                "\r\n",
                "#           784*16 weights                16*16 weights           16*10 weights                            <- #weights\r\n",
                "#               16 biases                    16 biases               10 biases                             <- #biases\r\n",
                "#          weights_2, biases_2         weights_3, biases_3      weights_4, biases_4\r\n",
                "\r\n",
                "class NN:\r\n",
                "\r\n",
                "    def __init__(self, layers, batch_size, step_size):\r\n",
                "        \"\"\"\r\n",
                "        Inits the neural network.\r\n",
                "\r\n",
                "        Parameters:\r\n",
                "            layers: [ layer1_n, layer2_n, layer3_n, ... ]\r\n",
                "        \"\"\"\r\n",
                "        # Set metadata\r\n",
                "        if not len(layers) >= 2:\r\n",
                "            raise TypeError(\r\n",
                "                \"Specify at least two layers for the neural network\")\r\n",
                "        self.batch_size = batch_size\r\n",
                "        self.count = 0\r\n",
                "        self.cost = 0\r\n",
                "        self.step_size = step_size\r\n",
                "\r\n",
                "        # Init neurons\r\n",
                "        self.neurons_z = [np.empty(0)] + [np.empty(n) for n in layers[1:]]\r\n",
                "        self.neurons = [np.empty(n) for n in layers]\r\n",
                "\r\n",
                "        # Init weights & biases\r\n",
                "        self.weights = [np.empty(0)] + [np.random.rand(len(self.neurons[i+1]), n2)\r\n",
                "                                        for i, n2 in enumerate(layers[:-1])]\r\n",
                "        self.biases = [np.empty(0)] + [np.random.rand(n) for n in layers[1:]]\r\n",
                "\r\n",
                "        # Init desired changes for backpropagation\r\n",
                "        self.weights_desired_changes = [np.empty(\r\n",
                "            0)] + [np.empty((layers[i+1], n2)) for i, n2 in enumerate(layers[:-1])]\r\n",
                "        self.biases_desired_changes = [\r\n",
                "            np.empty(0)] + [np.empty(n) for n in layers[1:]]\r\n",
                "\r\n",
                "    def train(self, input, desired):\r\n",
                "        # more desired values than output neurons\r\n",
                "        if desired >= len(self.neurons[-1]):\r\n",
                "            raise ValueError(\r\n",
                "                f\"Desired value is {desired} but must be smaller than {len(self.neurons[-1])}\")\r\n",
                "\r\n",
                "        # Feed forward & Propagate back\r\n",
                "        output = self._feed_forward(input)\r\n",
                "        self._propagate_back(output, desired)\r\n",
                "\r\n",
                "        # Calc cost\r\n",
                "        desired = encode_one_hot(desired, len(output))\r\n",
                "        self.cost += np.sum((outputs-desired)**2)\r\n",
                "\r\n",
                "        # Learn after <batch_size> trainings\r\n",
                "        self.count += 1\r\n",
                "        if self.count == batch_size:\r\n",
                "            # Get & reset cost\r\n",
                "            self.cost /= batch_size  # average\r\n",
                "            print(f\"C={self.cost}\")\r\n",
                "            self.cost = 0\r\n",
                "\r\n",
                "            # Learn\r\n",
                "            self._learn()\r\n",
                "\r\n",
                "            # Reset batch\r\n",
                "            self.count = 0\r\n",
                "\r\n",
                "    def _feed_forward(self, input):\r\n",
                "        \"\"\"Feed through neural network. Returns the output neurons\"\"\"\r\n",
                "        # Checks\r\n",
                "        if not isinstance(input, np.ndarray):\r\n",
                "            raise TypeError(f\"Input must be a ndarray\")\r\n",
                "        if not input.size == len(self.neurons[0]):\r\n",
                "            raise TypeError(\r\n",
                "                f\"Input contains {input.size} entries, however the input layer is expecting {len(self.neurons[0])} entries\")\r\n",
                "\r\n",
                "        # Set input layer\r\n",
                "        self.neurons[0] = input\r\n",
                "\r\n",
                "        # Feed forward through all layers, start with layer l=1\r\n",
                "        for l in range(1, len(self.neurons)):\r\n",
                "            self.neurons_z[l] = self.weights[l] @ self.neurons[l -\r\n",
                "                                                               1] + self.biases[l]\r\n",
                "            self.neurons[l] = self._activation(self.neurons_z[l])\r\n",
                "\r\n",
                "        # Return neurons of output layer\r\n",
                "        return self.neurons[-1]\r\n",
                "\r\n",
                "    def _propagate_back(self, output, desired):\r\n",
                "        \"\"\"\r\n",
                "        Propagates back the results and saves desired changes to weights and biases.\r\n",
                "        Note that we do not make any changes to weights or biases at this point yet (this is done in _learn()).\r\n",
                "        \"\"\"\r\n",
                "        # Go backwards through the layers and calculate gradient\r\n",
                "        delC_delActivation = None\r\n",
                "        delZ_delWeights = None\r\n",
                "\r\n",
                "        for l in range(len(self.neurons)-1, 0, -1):  # from layer l to 1\r\n",
                "            if l == len(self.neurons)-1:  # output layer\r\n",
                "                delC_delActivation = 2*(self.neurons[l]-desired)\r\n",
                "            else:\r\n",
                "                inner_prod = delC_delActivation * \\\r\n",
                "                    self._v_derive_activation(self.neurons_z[l+1])\r\n",
                "                delC_delActivation = [\r\n",
                "                    sum(inner_prod * self.weights[l+1][:, j]) for j in range(len(self.neurons[l]))\r\n",
                "                ]\r\n",
                "\r\n",
                "            delActivation_delZ = self._v_derive_activation(self.neurons_z[l])\r\n",
                "            dot_term = np.array(\r\n",
                "                [delC_delActivation * delActivation_delZ]).T  # column vector\r\n",
                "\r\n",
                "            delZ_delWeights = np.array([self.neurons[l-1]])  # row vector\r\n",
                "\r\n",
                "            delC_delWeights = dot_term @ delZ_delWeights\r\n",
                "            self.weights_desired_changes[l] += delC_delWeights\r\n",
                "\r\n",
                "    def _learn(self):\r\n",
                "        \"\"\"Do a gradient step after having gone through a mini batch\"\"\"\r\n",
                "        for l, weights_l_desired_changes in enumerate(self.weights_desired_changes):\r\n",
                "            # Get desired changes of weights & biases\r\n",
                "            # (average over the desired changes of each sample in the mini batch)\r\n",
                "            self.weights_desired_changes[l] = (weights_l_desired_changes / batch_size) # average\r\n",
                "            self.weights_desired_changes[l] *= -1 # negative gradient\r\n",
                "            self.weights_desired_changes[l] *= self.step_size # step size\r\n",
                "\r\n",
                "            # Adjust weights & biases to \"learn\"\r\n",
                "            self.weights[l] *= self.weights_desired_changes[l]\r\n",
                "\r\n",
                "\r\n",
                "    def _activation(self, vector):\r\n",
                "        # Sigmoid\r\n",
                "        # return np.array([sigmoid(x) for x in vector])\r\n",
                "\r\n",
                "        # ReLu\r\n",
                "        return np.array([relu(x) for x in vector])\r\n",
                "\r\n",
                "    def _derive_activation(self, x):\r\n",
                "        \"\"\"Calculates the derivative of the activation function\"\"\"\r\n",
                "        if x > 0:\r\n",
                "            return 1\r\n",
                "        else:\r\n",
                "            return 0\r\n",
                "\r\n",
                "    def _v_derive_activation(self, x):\r\n",
                "        \"\"\"Vectorized version of _derive_activation\"\"\"\r\n",
                "        return np.vectorize(self._derive_activation)(x)\r\n",
                "\r\n",
                "\r\n",
                "# --- Test with sample model\r\n",
                "# model = NN([16, 32])\r\n",
                "\r\n",
                "# print(len(model.neurons_z))\r\n",
                "# print(model.neurons_z[0].shape)\r\n",
                "# print(model.neurons_z[1].shape)\r\n",
                "\r\n",
                "# print(len(model.neurons))\r\n",
                "# print(model.neurons[0].shape)\r\n",
                "# print(model.neurons[1].shape)\r\n",
                "\r\n",
                "# print(len(model.weights))\r\n",
                "# print(model.weights[0].shape)\r\n",
                "# print(model.weights[1].shape)\r\n",
                "\r\n",
                "# print(len(model.biases))\r\n",
                "# print(model.biases[0].shape)\r\n",
                "# print(model.biases[1].shape)\r\n",
                "\r\n",
                "# model = NN([784, 16, 16, 10], 10, 0.1)\r\n",
                "# img_rand = np.random.randint(0, 256, size=(784,))\r\n",
                "# for i in range(10):\r\n",
                "#     model.train(img_rand, 2)\r\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Utility\r\n",
                "\r\n",
                "def normalize(x):\r\n",
                "    \"\"\"Normalizes the given array.\"\"\"\r\n",
                "    return x / max(x)\r\n",
                "\r\n",
                "def relu(x):\r\n",
                "    return max(0.0, x)\r\n",
                "\r\n",
                "def sigmoid(x):\r\n",
                "    \"Numerically stable sigmoid function.\"\r\n",
                "    if x >= 0:\r\n",
                "        z = np.exp(-x)\r\n",
                "        return 1 / (1 + z)\r\n",
                "    else:\r\n",
                "        # if x is less than zero then z will be small\r\n",
                "        # denominator can't be zero because it's 1+z\r\n",
                "        z = np.exp(x)\r\n",
                "        return z / (1 + z)\r\n",
                "\r\n",
                "def encode_one_hot(x, size):\r\n",
                "    return np.eye(size)[x]\r\n"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.7",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.0 64-bit"
        },
        "interpreter": {
            "hash": "be9a0cf467f139e4498e926d03e2930c406f1851a8d2de212e2cfa447dbf7c74"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}